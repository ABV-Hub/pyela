{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started with ELA\n",
    "\n",
    "We will be using data publicly available from the BoM and GA. Ackn, copyrights and the like to be included. \n",
    "\n",
    "Aiming to have a 3D grid of primary lithologies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-27T01:54:38.357642Z",
     "start_time": "2018-02-27T01:54:36.460827Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "import geopandas as gpd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ('ELA_SRC' in os.environ):\n",
    "    root_src_dir = os.environ['ELA_SRC']\n",
    "elif sys.platform == 'win32':\n",
    "    root_src_dir = r'C:\\src\\github_jm\\pyela'\n",
    "else:\n",
    "    root_src_dir = '/home/per202/src/github_jm/pyela'\n",
    "\n",
    "pkg_src_dir = root_src_dir\n",
    "sys.path.append(pkg_src_dir)\n",
    "\n",
    "\n",
    "from ela.textproc import *\n",
    "from ela.utils import *\n",
    "from ela.classification import *\n",
    "from ela.visual import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = os.environ['USER']\n",
    "data_path = os.path.join('/home', username, 'data')\n",
    "bungendore_raster = rasterio.open(os.path.join(data_path, 'ela/tmp/CLIP_reproj_UTM55.tif'))\n",
    "raster_projstring = \"+proj=utm +zone=55 +south +datum=WGS84 +units=m +no_defs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = os.path.join(data_path, 'gw_shp_murrumbidgee_river/shp_bungendore.shp')\n",
    "shape=gpd.read_file(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(bungendore_raster,title='East of Bungendore, AU', cmap='terrain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bidgee_path = os.path.join(data_path, 'gw_shp_murrumbidgee_river/shp_murrumbidgee_river')\n",
    "lithology_logs = pd.read_csv(os.path.join(bidgee_path, 'NGIS_LithologyLog.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lithology_logs.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subset to the location of interest\n",
    "\n",
    "The lithology logs are for all of the Murrumbidgee catchment. We subset to the location of interest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-06T00:50:36.439052Z",
     "start_time": "2018-02-06T00:50:36.434305Z"
    }
   },
   "outputs": [],
   "source": [
    "DEPTH_FROM_COL = 'FromDepth'\n",
    "DEPTH_TO_COL = 'ToDepth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-06T00:50:36.439052Z",
     "start_time": "2018-02-06T00:50:36.434305Z"
    }
   },
   "outputs": [],
   "source": [
    "TOP_ELEV_COL = 'TopElev'\n",
    "BOTTOM_ELEV_COL = 'BottomElev'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LITHO_DESC_COL = 'Description'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-06T00:50:36.439052Z",
     "start_time": "2018-02-06T00:50:36.434305Z"
    }
   },
   "outputs": [],
   "source": [
    "df = lithology_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Curious that ~2500 data points do not have their AHD height but their depth. \n",
    "\n",
    "While this can be remediated, we should maybe hold off since the domain upon which we will work is small compared to the full spatial extent of the data set. So, let's subset the logs based on spatial locations, to keep only those \"nearby\" the DEM we have near the locality of Bungendore in this case study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shape_reproj = shape.to_crs(epsg=4283)\n",
    "shape_reproj = shape.to_crs(raster_projstring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_reproj.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geoloc = get_coords_from_gpd_shape(shape_reproj)\n",
    "geoloc[\"HydroCode\"] = shape_reproj[\"HydroCode\"]\n",
    "geoloc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(geoloc), len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, geoloc, how='inner', on=\"HydroCode\", sort=False, copy=True, indicator=False, validate=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[EASTING_COL] = df['x']\n",
    "df[NORTHING_COL] = df['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Round up 'depth to' and 'depth from' columns\n",
    "\n",
    "We round the depth related columns to the upper integer value and drop the entries where the resulting depths have degenerated to 0. We first clean up height/depths columns to make sure they are numeric.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def as_numeric(x):\n",
    "    if isinstance(x, float):\n",
    "        return x\n",
    "    if x == 'None':\n",
    "        return np.nan\n",
    "    elif x is None:\n",
    "        return np.nan\n",
    "    elif isinstance(x, str):\n",
    "        return float(x)\n",
    "    else:\n",
    "        return float(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[DEPTH_FROM_COL] = df[DEPTH_FROM_COL].apply(as_numeric)\n",
    "df[DEPTH_TO_COL] = df[DEPTH_TO_COL].apply(as_numeric)\n",
    "df[TOP_ELEV_COL] = df[TOP_ELEV_COL].apply(as_numeric)\n",
    "df[BOTTOM_ELEV_COL] = df[BOTTOM_ELEV_COL].apply(as_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dr = DepthsRounding(DEPTH_FROM_COL, DEPTH_TO_COL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dr.round_to_metre_depths(df, np.round, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descs = df[LITHO_DESC_COL]\n",
    "descs = descs.reset_index()\n",
    "descs = descs[LITHO_DESC_COL]\n",
    "descs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The description column as read seems to be objects. Other columns seem to be objects when they should be numeric. We define two functions to clean these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_desc(x):\n",
    "    if isinstance(x, float):\n",
    "        return ''\n",
    "    elif x is None:\n",
    "        return ''\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [clean_desc(x) for x in descs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from striplog import Lexicon\n",
    "lex = Lexicon.default()\n",
    "\n",
    "y = clean_lithology_descriptions(y, lex)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get a flat list of all the \"tokens\" but remove stop words ('s', 'the' and the like)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = v_lower(y)\n",
    "vt = v_word_tokenize(y)\n",
    "flat = np.concatenate(vt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoplist = stopwords.words('english')\n",
    "exclude = stoplist + ['.',',',';',':','(',')','-']\n",
    "flat = [word for word in flat if word not in exclude]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(flat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_most_common= token_freq(flat, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_freq(df_most_common)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are terms such as 'sandy', 'clayey', 'silty' and so on. Let's define functions to detect terms derived from lithology classes, and their frequency. Given the likely skewness, we use a y log scale. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_freq_for_root(flat, 'sand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_freq_for_root(flat, 'clay')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add a section that defines additional clean up e.g. 'sand/clay/soil' or dashed union composite terms\n",
    "# split_composite_term('sand/clay/soil', '/').replace('/', ' / ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_most_common"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the list of most common tokens, we may want to define lithology classes as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[LITHO_DESC_COL] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lithologies = ['clay','sand','gravel','granite','shale','silt','topsoil','loam','soil','slate','sandstone']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And to capture any of these we devise a regular expression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "any_litho_markers_re = r'sand|clay|ston|shale|silt|granit|soil|gravel|loam|slate'\n",
    "regex = re.compile(any_litho_markers_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_lithologies_numclasses = create_numeric_classes(lithologies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lithologies_dict = dict([(x,x) for x in lithologies])\n",
    "lithologies_dict['sands'] = 'sand'\n",
    "lithologies_dict['clays'] = 'clay'\n",
    "lithologies_dict['shales'] = 'shale'\n",
    "lithologies_dict['claystone'] = 'clay'\n",
    "lithologies_dict['siltstone'] = 'silt'\n",
    "lithologies_dict['limesand'] = 'sand' # ??\n",
    "lithologies_dict['calcarenite'] = 'limestone' # ??\n",
    "lithologies_dict['calcitareous'] = 'limestone' # ??\n",
    "lithologies_dict['mudstone'] = 'silt' # ??\n",
    "lithologies_dict['capstone'] = 'limestone' # ??\n",
    "lithologies_dict['ironstone'] = 'sandstone' # ??\n",
    "#lithologies_dict['topsoil'] = 'soil' # ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lithologies_adjective_dict = {\n",
    "    'sandy' :  'sand',\n",
    "    'clayey' :  'clay',\n",
    "    'clayish' :  'clay',\n",
    "    'shaley' :  'shale',\n",
    "    'silty' :  'silt',\n",
    "    'gravelly' :  'gravel'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_tokens = v_word_tokenize(y)\n",
    "litho_terms_detected = v_find_litho_markers(v_tokens, regex=regex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if we detect these lithology markers in each bore log entries  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_mark = [x for x in litho_terms_detected if len(x) == 0 ]\n",
    "at_least_one_mark = [x for x in litho_terms_detected if len(x) >= 1]\n",
    "at_least_two_mark = [x for x in litho_terms_detected if len(x) >= 2]\n",
    "print('There are %s entries with no marker, %s entries with at least one, %s with at least two'%(len(zero_mark),len(at_least_one_mark),len(at_least_two_mark)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: probably need to think of precanned facilities in ela to assess the detection rate in such EDA. Maybe wordcloud not such a bad idea too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descs_zero_mark = [y[i] for i in range(len(litho_terms_detected)) if len(litho_terms_detected[i]) == 0 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descs_zero_mark[1:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_litho = v_find_primary_lithology(litho_terms_detected, lithologies_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "secondary_litho = v_find_secondary_lithology(litho_terms_detected, primary_litho, lithologies_adjective_dict, lithologies_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[PRIMARY_LITHO_COL]=primary_litho\n",
    "df[SECONDARY_LITHO_COL]=secondary_litho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[PRIMARY_LITHO_NUM_COL] = v_to_litho_class_num(primary_litho, my_lithologies_numclasses)\n",
    "df[SECONDARY_LITHO_NUM_COL] = v_to_litho_class_num(secondary_litho, my_lithologies_numclasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting depth below ground to Australian Height Datum elevation\n",
    "\n",
    "While the bore entries have columns for AHD elevations, many appear to be missing data. Since we have a DEM of the region we can correct this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd = HeightDatumConverter(bungendore_raster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cd.add_height(df, \n",
    "        depth_from_col=DEPTH_FROM_COL, depth_to_col=DEPTH_TO_COL, \n",
    "        depth_from_ahd_col=DEPTH_FROM_AHD_COL, depth_to_ahd_col=DEPTH_TO_AHD_COL, \n",
    "        easting_col=\"x\", northing_col=\"y\", drop_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding lithology classes\n",
    "\n",
    "### Visualise lithology classes\n",
    "\n",
    "## Interpolate over a regular grid\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-06T00:50:58.799366Z",
     "start_time": "2018-02-06T00:50:55.503766Z"
    }
   },
   "outputs": [],
   "source": [
    "# max/min bounds\n",
    "shp_bbox = get_bbox(shape_reproj)\n",
    "shp_bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raster_bbox = bungendore_raster.bounds\n",
    "raster_bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_min = max(shp_bbox[0], raster_bbox[0])\n",
    "x_max = min(shp_bbox[2], raster_bbox[2])\n",
    "y_min = max(shp_bbox[1], raster_bbox[1])\n",
    "y_max = min(shp_bbox[3], raster_bbox[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_res = 150\n",
    "m = create_meshgrid_cartesian(x_min, x_max, y_min, y_max, grid_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x.shape for x in m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-06T00:50:58.799366Z",
     "start_time": "2018-02-06T00:50:55.503766Z"
    }
   },
   "outputs": [],
   "source": [
    "dem_array = surface_array(bungendore_raster, x_min, y_min, x_max, y_max, grid_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-06T00:50:58.799366Z",
     "start_time": "2018-02-06T00:50:55.503766Z"
    }
   },
   "outputs": [],
   "source": [
    "dem_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(to_carto(dem_array), cmap='terrain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-06T00:50:58.799366Z",
     "start_time": "2018-02-06T00:50:55.503766Z"
    }
   },
   "outputs": [],
   "source": [
    "dem_array_data = {'bounds': (x_min, x_max, y_min, y_max), 'grid_res': grid_res, 'mesh_xy': m, 'dem_array': dem_array}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bins=100\n",
    "p = df.hist(column=[DEPTH_FROM_AHD_COL,DEPTH_TO_AHD_COL], sharex=True, sharey=True, bins=n_bins, figsize=(15,5))\n",
    "for axes in p:\n",
    "    axes[0].set_yscale(\"log\", nonposy='clip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbours=10\n",
    "ahd_min=620\n",
    "ahd_max=830\n",
    "\n",
    "z_ahd_coords = np.arange(ahd_min,ahd_max,1)\n",
    "dim_x,dim_y = m[0].shape\n",
    "dim_z = len(z_ahd_coords)\n",
    "dims = (dim_x,dim_y,dim_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lithology_3d_array=np.empty(dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gi = GridInterpolation(easting_col='x', northing_col='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gi.interpolate_volume(lithology_3d_array, df, PRIMARY_LITHO_NUM_COL, z_ahd_coords, n_neighbours, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Burn DEM into grid\n",
    "z_index_for_ahd = z_index_for_ahd_functor(b=-ahd_min)\n",
    "# check that we get the expected indexes for an AHD height\n",
    "z_index_for_ahd(800), z_index_for_ahd(+630)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dem_array.shape, m[0].shape, lithology_3d_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "burn_volume(lithology_3d_array, dem_array, z_index_for_ahd, below=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lithologies =           ['clay',  'sand',      'gravel',    'granite', 'shale',  'silt',           'topsoil',      'loam',     'soil',    'slate',      'sandstone']\n",
    "lithology_color_names = ['olive', 'yellow', 'lightgrey',      'dimgray', 'teal',  'cornsilk',     'saddlebrown', 'rosybrown', 'chocolate', 'lightslategrey', 'gold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lithology_cmap = discrete_classes_colormap(lithology_color_names) # Later for exporting to RGB geotiffs??\n",
    "litho_legend_display_info = [(lithology_cmap[i], lithologies[i], lithology_color_names[i]) for i in range(len(lithologies))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "litho_legend = legend_fig(litho_legend_display_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cms = cartopy_color_settings(lithology_color_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgplot = plt.imshow(to_carto(lithology_3d_array[:, :, z_index_for_ahd(660)]), cmap=cms['cmap'])\n",
    "title = plt.title('Primary litho at +660mAHD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgplot = plt.imshow(to_carto(lithology_3d_array[:, :, z_index_for_ahd(700)]), cmap=cms['cmap'])\n",
    "title = plt.title('Primary litho at +700mAHD')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ela.visual3d import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx, yy = dem_array_data['mesh_xy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mayavi import mlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mlab.figure(size=(800, 800))\n",
    "#mlab.surf(xx, yy, dem_array, warp_scale=20, colormap='terrain')\n",
    "#mlab.outline()\n",
    "#mlab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_litho = LithologiesClassesVisual3d(lithologies, lithology_color_names, 'black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vis_litho.render_classes_planar(lithology_3d_array, 'Primary lithology')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lithology_3d_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vis_litho.render_class(lithology_3d_array, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df.fillna({PRIMARY_LITHO_NUM_COL: -1.0})\n",
    "df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = df_1[(df_1[DEPTH_TO_AHD_COL] > (ahd_min-20))]\n",
    "len(df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The factor to apply to Z coordinates, otherwise things would be squashed visually. \n",
    "# Would prefer a visual only scaling factor, but could not find a way to do so. \n",
    "Z_SCALING = 20.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_coords = np.arange(ahd_min,ahd_max,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay_vis_k = LithologiesClassesOverlayVisual3d(lithologies, lithology_color_names, 'black', dem_array_data, z_coords, Z_SCALING, df_2, PRIMARY_LITHO_NUM_COL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_class(value):\n",
    "    f = overlay_vis_k.view_overlay(value, lithology_3d_array)\n",
    "    return f\n",
    "\n",
    "f = view_class(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = view_class(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = view_class(2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = view_class(3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = view_class(4.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = view_class(5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = view_class(2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = view_class(2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = view_class(2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sops = SliceOperation(dem_array, z_index_for_ahd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trial stuff:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape.plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected frustrating to do something simple like an overlay in Python (yearning for R's ggmap). Google with keywords \"overlay a rasterio with geopandas points\".\n",
    "For future reference perhaps https://geohackweek.github.io/vector/06-geopandas-advanced/  . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, figsize=(10, 6))\n",
    "ax.set_axis_off()\n",
    "plt.axis('equal')\n",
    "rasterio.plot.show((bungendore_raster, 1), title='East of Bungendore, AU', cmap='terrain')\n",
    "shape.plot()\n",
    "#    column='pfaf_6', markersize=30, \n",
    "#                               categorical=True, legend=True, ax=ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://gis.stackexchange.com/questions/294072/how-can-i-superimpose-a-geopandas-dataframe-on-a-raster-plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 15))\n",
    "# fig, ax = plt.subplots()\n",
    "rasterio.plot.show(bungendore_raster, ax=ax, title='East of Bungendore, AU', cmap='terrain')\n",
    "shape_reproj.plot(ax=ax, facecolor='orange')\n",
    "# shape_reproj.plot(ax=ax, facecolor='none', edgecolor='red')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We extract a portion of the dem over the bounding box of the groundwater areas of interest, and save DEM data as numpy arrays that will be more convenient to work with in mayavi (with x=easting and y=northing) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (ELA)",
   "language": "python",
   "name": "ela"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
